{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRL Custom Training Process Test\n",
    "\n",
    "Testing customized PPO training with a small model (GPT-2) to validate our approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at openai-community/gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    get_scheduler,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "from trl import PPOConfig, PPOTrainer, create_reference_model, AutoModelForCausalLMWithValueHead\n",
    "from datasets import load_dataset\n",
    "from typing import List, Dict, Any, Optional\n",
    "import numpy as np\n",
    "\n",
    "# MODEL_NAME = \"EleutherAI/pythia-1b-deduped\"  # Using small GPT-2 for testing\n",
    "MODEL_NAME = \"openai-community/gpt2\"\n",
    "\n",
    "# Load models and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load main model\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "reward_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=1\n",
    ")\n",
    "ref_model = create_reference_model(model)\n",
    "# ref_mode = None\n",
    "value_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "from datasets import DatasetDict\n",
    "\n",
    "\n",
    "DATASET_NAME = \"trl-internal-testing/sentiment-trl-style\"  # Simple sentiment dataset\n",
    "\n",
    "dataset: DatasetDict = load_dataset(DATASET_NAME)\n",
    "train_dataset = dataset['train']\n",
    "test_dataset = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset: DatasetDict, tokenizer):\n",
    "    \"\"\"pre-tokenize the dataset before training; only collate during training\"\"\"\n",
    "\n",
    "    def tokenize(element):\n",
    "        input_ids = tokenizer(\n",
    "            element[\"prompt\"]\n",
    "        )\n",
    "        return {\"input_ids\": input_ids['input_ids'], \"lengths\": len(input_ids)}\n",
    "\n",
    "    return dataset.map(\n",
    "        tokenize,\n",
    "        remove_columns=dataset.column_names,\n",
    "    )\n",
    "\n",
    "preprocessed_train = prepare_dataset(train_dataset, tokenizer)\n",
    "preprocessed_test = prepare_dataset(test_dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1544,\n",
       " 750,\n",
       " 407,\n",
       " 588,\n",
       " 1243,\n",
       " 543,\n",
       " 14516,\n",
       " 683,\n",
       " 326,\n",
       " 339,\n",
       " 550,\n",
       " 1752,\n",
       " 587,\n",
       " 407,\n",
       " 691,\n",
       " 2354,\n",
       " 262,\n",
       " 10393,\n",
       " 5002,\n",
       " 475,\n",
       " 772,\n",
       " 2354,\n",
       " 262,\n",
       " 5535,\n",
       " 13,\n",
       " 679,\n",
       " 750,\n",
       " 407,\n",
       " 1464,\n",
       " 588,\n",
       " 20920,\n",
       " 2035,\n",
       " 13,\n",
       " 2399,\n",
       " 9476,\n",
       " 287,\n",
       " 852,\n",
       " 351,\n",
       " 683,\n",
       " 373,\n",
       " 407,\n",
       " 326,\n",
       " 3297,\n",
       " 286,\n",
       " 9476,\n",
       " 13,\n",
       " 198,\n",
       " 198,\n",
       " 1,\n",
       " 5297,\n",
       " 553,\n",
       " 531,\n",
       " 20920,\n",
       " 13,\n",
       " 366,\n",
       " 35,\n",
       " 1697,\n",
       " 36363,\n",
       " 373,\n",
       " 534,\n",
       " 4039,\n",
       " 8976,\n",
       " 13]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_train['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Generator, Never\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(\n",
    "    preprocessed_train,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=None,\n",
    "    drop_last=True,  # needed; otherwise the last batch will be of ragged shape\n",
    ")\n",
    "def repeat_generator() -> Generator[Any, Any, Never]:\n",
    "    while True:\n",
    "        yield from dataloader\n",
    "\n",
    "iter_dataloader = iter(repeat_generator())\n",
    "next(iter_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG LIB : <torch.utils.data.dataloader.DataLoader object at 0x7fb0196b9c70>\n",
      "DEBUG LIB2 : <accelerate.data_loader.DataLoaderShard object at 0x7fb013126ba0>\n",
      "DEBUG LIB3 : <accelerate.data_loader.DataLoaderShard object at 0x7fb013126ba0>\n",
      "DEBUG LIB4 : {'input_ids': tensor([[ 1639,  3088,   284,  ..., 50256, 50256, 50256],\n",
      "        [    1,  1639,  1297,  ..., 50256, 50256, 50256],\n",
      "        [18565,    11,   198,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [ 2504,   373,  1239,  ..., 50256, 50256, 50256],\n",
      "        [  464,  8796,   373,  ...,    13, 50256, 50256],\n",
      "        [  464, 16570,  7342,  ..., 50256, 50256, 50256]], device='cuda:0'), 'lengths': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "DEBUG LIB4 : <generator object PPOTrainer.train.<locals>.repeat_generator at 0x7fb01975abc0>\n",
      "DEBUG LIB5 : {'input_ids': tensor([[43625,    11,   884,  ...,  5416,    13, 50256],\n",
      "        [ 6423,   339,  4376,  ..., 50256, 50256, 50256],\n",
      "        [   40,  3066,   284,  ..., 50256, 50256, 50256],\n",
      "        ...,\n",
      "        [   54, 18998,   262,  ..., 50256, 50256, 50256],\n",
      "        [20459, 28459,  3114,  ..., 50256, 50256, 50256],\n",
      "        [    1,  1135,  1183,  ..., 50256, 50256, 50256]], device='cuda:0'), 'lengths': tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}\n",
      "===training policy===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meryaw\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/d/Code/Py/research/finetuning_lm_from_human_preferences/examples/wandb/run-20250409_195517-lx2lrimn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eryaw/huggingface/runs/lx2lrimn' target=\"_blank\">ppo_config__42__1744203315</a></strong> to <a href='https://wandb.ai/eryaw/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eryaw/huggingface' target=\"_blank\">https://wandb.ai/eryaw/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eryaw/huggingface/runs/lx2lrimn' target=\"_blank\">https://wandb.ai/eryaw/huggingface/runs/lx2lrimn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/7 : < :, Epoch 0.00/0.020032051282051284]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> query                                       </span>┃<span style=\"font-weight: bold\"> model response                              </span>┃<span style=\"font-weight: bold\"> score               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ This is just the first time you almost ran  │  I'm not sure if I'm going to be able to do │ -5.663218021392822  │\n",
       "│ over him. I bet that was a bit of a         │ it again, but I'm sure I'll be able to do   │                     │\n",
       "│ surprise.\"                                  │ it again.\"                                  │                     │\n",
       "│                                             │                                             │                     │\n",
       "│ Ella finally relaxed and a chuckle escaped  │ \"I'm sure you're going to be able to do it  │                     │\n",
       "│ her. \"It was pretty funny, now that I think │ again, too.\"                                │                     │\n",
       "│ about it.                                   │                                             │                     │\n",
       "│                                             │ \"I'm                                        │                     │\n",
       "├─────────────────────────────────────────────┼─────────────────────────────────────────────┼─────────────────────┤\n",
       "│ His father had told him not to tell anyone  │                                             │ -5.5836710929870605 │\n",
       "│ about his dreams, and he had. One by one,   │                                             │                     │\n",
       "│ he was violating every rule in his life.    │ \"He's the only one looking,\" Blue said.     │                     │\n",
       "│                                             │                                             │                     │\n",
       "│ Of course someone was looking. Of course    │ \"He's the only one looking,\" Blue said.     │                     │\n",
       "│ they had found him.                         │                                             │                     │\n",
       "│                                             │ \"He's the only one looking,\" Blue said.     │                     │\n",
       "│ \"He's not the only one looking,\" Blue said  │                                             │                     │\n",
       "│ suddenly.                                   │ \"He's the only one looking,\" Blue said.     │                     │\n",
       "│                                             │                                             │                     │\n",
       "├─────────────────────────────────────────────┼─────────────────────────────────────────────┼─────────────────────┤\n",
       "│ A fine plan that was interrupted by the     │                                             │ -4.447566509246826  │\n",
       "│ blond-haired berserker who almost instantly │                                             │                     │\n",
       "│ joined him near a marble fountain.          │ \"I'm sorry, but I'm not going to let you    │                     │\n",
       "│                                             │ go,\" he said, his voice trembling. \"I'm not │                     │\n",
       "│ Cyn had proven to be invaluable help when   │ going to let you go. I'm not going to let   │                     │\n",
       "│ they'd arrived at Styx's lair with a gaggle │ you go. I'm not going to let you go. I      │                     │\n",
       "│ of terrified fey.                           │                                             │                     │\n",
       "├─────────────────────────────────────────────┼─────────────────────────────────────────────┼─────────────────────┤\n",
       "│ He'd gone to the police, and he'd been      │                                             │ -4.560464382171631  │\n",
       "│ working with them since to uncover the      │                                             │                     │\n",
       "│ assholes behind it. Now they'd succeeded,   │ \"I'm not going to let you go,\" Declan said. │                     │\n",
       "│ and those assholes were unhappy with        │ \"I'm going to tell you what I know. I'm     │                     │\n",
       "│ Declan. They wanted revenge and to make an  │ going to tell you what I know. I'm going to │                     │\n",
       "│ example of him, preferably before the case  │ tell you what I know. I'm going to tell you │                     │\n",
       "│ came to trial in three weeks' time.         │                                             │                     │\n",
       "├─────────────────────────────────────────────┼─────────────────────────────────────────────┼─────────────────────┤\n",
       "│ \"What's going on? Is everything all right?\" │  I'm just going to draw it. I'm going to    │ -6.481200218200684  │\n",
       "│                                             │ draw it. I'm going to draw it. I'm going to │                     │\n",
       "│ \"I was drawing,\" she said in a low voice.   │ draw it. I'm going to draw it. I'm going to │                     │\n",
       "│ So low that both men leaned forward to      │ draw it. I'm going to draw it. I'm going    │                     │\n",
       "│ hear. \"I wanted to draw Callie's Meadow for │                                             │                     │\n",
       "│ Callie. It's not much.                      │                                             │                     │\n",
       "└─────────────────────────────────────────────┴─────────────────────────────────────────────┴─────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mquery                                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmodel response                             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mscore              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ This is just the first time you almost ran  │  I'm not sure if I'm going to be able to do │ -5.663218021392822  │\n",
       "│ over him. I bet that was a bit of a         │ it again, but I'm sure I'll be able to do   │                     │\n",
       "│ surprise.\"                                  │ it again.\"                                  │                     │\n",
       "│                                             │                                             │                     │\n",
       "│ Ella finally relaxed and a chuckle escaped  │ \"I'm sure you're going to be able to do it  │                     │\n",
       "│ her. \"It was pretty funny, now that I think │ again, too.\"                                │                     │\n",
       "│ about it.                                   │                                             │                     │\n",
       "│                                             │ \"I'm                                        │                     │\n",
       "├─────────────────────────────────────────────┼─────────────────────────────────────────────┼─────────────────────┤\n",
       "│ His father had told him not to tell anyone  │                                             │ -5.5836710929870605 │\n",
       "│ about his dreams, and he had. One by one,   │                                             │                     │\n",
       "│ he was violating every rule in his life.    │ \"He's the only one looking,\" Blue said.     │                     │\n",
       "│                                             │                                             │                     │\n",
       "│ Of course someone was looking. Of course    │ \"He's the only one looking,\" Blue said.     │                     │\n",
       "│ they had found him.                         │                                             │                     │\n",
       "│                                             │ \"He's the only one looking,\" Blue said.     │                     │\n",
       "│ \"He's not the only one looking,\" Blue said  │                                             │                     │\n",
       "│ suddenly.                                   │ \"He's the only one looking,\" Blue said.     │                     │\n",
       "│                                             │                                             │                     │\n",
       "├─────────────────────────────────────────────┼─────────────────────────────────────────────┼─────────────────────┤\n",
       "│ A fine plan that was interrupted by the     │                                             │ -4.447566509246826  │\n",
       "│ blond-haired berserker who almost instantly │                                             │                     │\n",
       "│ joined him near a marble fountain.          │ \"I'm sorry, but I'm not going to let you    │                     │\n",
       "│                                             │ go,\" he said, his voice trembling. \"I'm not │                     │\n",
       "│ Cyn had proven to be invaluable help when   │ going to let you go. I'm not going to let   │                     │\n",
       "│ they'd arrived at Styx's lair with a gaggle │ you go. I'm not going to let you go. I      │                     │\n",
       "│ of terrified fey.                           │                                             │                     │\n",
       "├─────────────────────────────────────────────┼─────────────────────────────────────────────┼─────────────────────┤\n",
       "│ He'd gone to the police, and he'd been      │                                             │ -4.560464382171631  │\n",
       "│ working with them since to uncover the      │                                             │                     │\n",
       "│ assholes behind it. Now they'd succeeded,   │ \"I'm not going to let you go,\" Declan said. │                     │\n",
       "│ and those assholes were unhappy with        │ \"I'm going to tell you what I know. I'm     │                     │\n",
       "│ Declan. They wanted revenge and to make an  │ going to tell you what I know. I'm going to │                     │\n",
       "│ example of him, preferably before the case  │ tell you what I know. I'm going to tell you │                     │\n",
       "│ came to trial in three weeks' time.         │                                             │                     │\n",
       "├─────────────────────────────────────────────┼─────────────────────────────────────────────┼─────────────────────┤\n",
       "│ \"What's going on? Is everything all right?\" │  I'm just going to draw it. I'm going to    │ -6.481200218200684  │\n",
       "│                                             │ draw it. I'm going to draw it. I'm going to │                     │\n",
       "│ \"I was drawing,\" she said in a low voice.   │ draw it. I'm going to draw it. I'm going to │                     │\n",
       "│ So low that both men leaned forward to      │ draw it. I'm going to draw it. I'm going    │                     │\n",
       "│ hear. \"I wanted to draw Callie's Meadow for │                                             │                     │\n",
       "│ Callie. It's not much.                      │                                             │                     │\n",
       "└─────────────────────────────────────────────┴─────────────────────────────────────────────┴─────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     12\u001b[39m trainer = PPOTrainer(\n\u001b[32m     13\u001b[39m     args=ppo_config,\n\u001b[32m     14\u001b[39m     processing_class=tokenizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m     21\u001b[39m     eval_dataset=preprocessed_test\n\u001b[32m     22\u001b[39m )\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# Add learning rate scheduler\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/finetuning-lm-from-human-preferences-4SAAosyV-py3.12/lib/python3.12/site-packages/trl/trainer/ppo_trainer.py:613\u001b[39m, in \u001b[36mPPOTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    606\u001b[39m         \u001b[38;5;28;01mdel\u001b[39;00m (\n\u001b[32m    607\u001b[39m             output, vpred_temp, logits, new_logprobs, vpred, vpredclipped,\n\u001b[32m    608\u001b[39m             vf_losses1, vf_losses2, vf_loss, vf_clipfrac, logprobs_diff, ratio, pg_losses, pg_losses2, pg_loss_max,\n\u001b[32m    609\u001b[39m             pg_loss, loss, pg_clipfrac, prob_dist, entropy, approxkl, mb_return,\n\u001b[32m    610\u001b[39m             mb_advantage, mb_values, mb_responses, mb_query_responses, mb_logprobs,\n\u001b[32m    611\u001b[39m         )\n\u001b[32m    612\u001b[39m         \u001b[38;5;66;03m# fmt: on\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m         \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m    615\u001b[39m     mean_kl = kl.sum(\u001b[32m1\u001b[39m).mean()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/finetuning-lm-from-human-preferences-4SAAosyV-py3.12/lib/python3.12/site-packages/torch/cuda/memory.py:218\u001b[39m, in \u001b[36mempty_cache\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[32m    208\u001b[39m \u001b[33;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[32m    209\u001b[39m \u001b[33;03m`nvidia-smi`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    215\u001b[39m \u001b[33;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[32m    216\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Initialize trainer\n",
    "ppo_config = PPOConfig(\n",
    "    learning_rate=3e-6,\n",
    "    output_dir='checkpoints/',\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=4,  # Effective batch size = 16\n",
    "    total_episodes=100,  # Small number for testing\n",
    "    max_steps=20,\n",
    "    cliprange=0.2,\n",
    "    missing_eos_penalty=1.0\n",
    ")\n",
    "trainer = PPOTrainer(\n",
    "    args=ppo_config,\n",
    "    processing_class=tokenizer,\n",
    "    value_model=value_model,\n",
    "    model=model,\n",
    "    ref_model=ref_model,\n",
    "    reward_model=reward_model,\n",
    "    train_dataset=preprocessed_train,\n",
    "    # data_collator: Optional[DataCollatorWithPadding] = None,\n",
    "    eval_dataset=preprocessed_test\n",
    ")\n",
    "\n",
    "# Add learning rate scheduler\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test generation with trained model\n",
    "test_prompt = \"Write a positive review: \"\n",
    "inputs = tokenizer(test_prompt, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_new_tokens=50,\n",
    "        do_sample=True,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "print(\"Generated text:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetuning-lm-from-human-preferences-4SAAosyV-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
