{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anthropic/hh-rlhf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"data/hh-rlhf\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['test'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openai/summarize_from_feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"openai/summarize_from_feedback\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openai original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "\n",
    "# MODEL_NAME = 'openai-community/gpt2-large' TODO: change to gpt2-large\n",
    "MODEL_NAME = 'openai-community/gpt2'\n",
    "PROJECT_DIR = '../'\n",
    "\n",
    "DATA_FILENAME = [\n",
    "    'cnndm_offline_60k.json',\n",
    "    'cnndm_online_45k.json',\n",
    "    'descriptiveness_offline_5k.json',\n",
    "    'sentimen_offline_5k.json',\n",
    "    'tldr_offline_60k.json',\n",
    "    'tldr_online_45k.json'\n",
    "]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== cnndm_offline_60k.json: 60588 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>sample0</th>\n",
       "      <th>sample1</th>\n",
       "      <th>sample2</th>\n",
       "      <th>sample3</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[7571, 1528, 878, 1992, 8732, 2486, 338, 717, ...</td>\n",
       "      <td>[1992, 2486, 338, 6146, 316, 4395, 4590, 373, ...</td>\n",
       "      <td>[2486, 468, 257, 6146, 316, 4395, 20005, 11, 4...</td>\n",
       "      <td>[383, 2635, 2097, 2716, 257, 4286, 286, 1992, ...</td>\n",
       "      <td>[1992, 2486, 468, 645, 2126, 644, 339, 338, 18...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[32, 10614, 5858, 14716, 24105, 656, 257, 6908...</td>\n",
       "      <td>[317, 10614, 5858, 14716, 24105, 656, 257, 690...</td>\n",
       "      <td>[383, 10614, 5858, 286, 257, 3155, 287, 28847,...</td>\n",
       "      <td>[317, 15291, 10614, 5858, 373, 14716, 5710, 65...</td>\n",
       "      <td>[317, 10614, 5858, 14716, 5710, 656, 257, 6908...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[10364, 8732, 2486, 284, 8279, 625, 262, 4960,...</td>\n",
       "      <td>[383, 471, 13, 50, 13, 1893, 318, 262, 717, 55...</td>\n",
       "      <td>[2486, 318, 257, 1256, 25242, 621, 262, 4960, ...</td>\n",
       "      <td>[383, 1893, 373, 21272, 416, 16755, 1524, 1719...</td>\n",
       "      <td>[383, 1893, 373, 21272, 416, 16755, 1524, 1719...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  [7571, 1528, 878, 1992, 8732, 2486, 338, 717, ...   \n",
       "1  [32, 10614, 5858, 14716, 24105, 656, 257, 6908...   \n",
       "2  [10364, 8732, 2486, 284, 8279, 625, 262, 4960,...   \n",
       "\n",
       "                                             sample0  \\\n",
       "0  [1992, 2486, 338, 6146, 316, 4395, 4590, 373, ...   \n",
       "1  [317, 10614, 5858, 14716, 24105, 656, 257, 690...   \n",
       "2  [383, 471, 13, 50, 13, 1893, 318, 262, 717, 55...   \n",
       "\n",
       "                                             sample1  \\\n",
       "0  [2486, 468, 257, 6146, 316, 4395, 20005, 11, 4...   \n",
       "1  [383, 10614, 5858, 286, 257, 3155, 287, 28847,...   \n",
       "2  [2486, 318, 257, 1256, 25242, 621, 262, 4960, ...   \n",
       "\n",
       "                                             sample2  \\\n",
       "0  [383, 2635, 2097, 2716, 257, 4286, 286, 1992, ...   \n",
       "1  [317, 15291, 10614, 5858, 373, 14716, 5710, 65...   \n",
       "2  [383, 1893, 373, 21272, 416, 16755, 1524, 1719...   \n",
       "\n",
       "                                             sample3  best  \n",
       "0  [1992, 2486, 468, 645, 2126, 644, 339, 338, 18...     2  \n",
       "1  [317, 10614, 5858, 14716, 5710, 656, 257, 6908...     2  \n",
       "2  [383, 1893, 373, 21272, 416, 16755, 1524, 1719...     2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Two days before President Barack Obama's first trip outside Washington to promote his gun-control proposals, the White House tried on Saturday to settle a brewing mystery by releasing a photo to back his claim to be a skeet shooter.\n",
      "\n",
      "Obama had set inquiring minds spinning when, in an interview with The New Republic magazine, he answered 'yes' when asked if he had ever fired a gun. The admission came as a surprise to many.\n",
      "\n",
      "'Yes, in fact, up at Camp David, we do skeet shooting all the time,' Obama said in the interview released last weekend, referring to the official presidential retreat in rural Maryland, which he last visited in October while campaigning for re-election.\n",
      "\n",
      "Guns a blazing: The White House released this picture, taken on Aug. 4, of the president skeet shooting after skeptics questioned Mr Obama's claim that he enjoyed shooting at Camp David\n",
      "\n",
      "Former White House senior adviser David Plouffe took to Twitter to mock those who might claim the photograph of President Obama shooting a firearm is fake\n",
      "\n",
      "White House communications director Dan Pfeiffer joined in the teasing by posting the Obama pic from his official Twitter account\n",
      "\n",
      "George W. Bush looks to the sky during a dove hunt in Hockley, Texas in 2004\n",
      "\n",
      "Asked whether the entire family participates, the president said: 'Not the girls, but oftentimes guests of mine go up there.'\n",
      "\n",
      "Then on Saturday morning, the White House released the photo of Obama \n",
      "shooting at clay pigeons at the presidential retreat at Camp David in \n",
      "Maryland.\n",
      "\n",
      "Former White House senior adviser David Plouffe couldn't resist mocking those who might claim the photograph of President \n",
      "Obama shooting was fake and tweeted: 'Attention skeet birthers. Make our day - let the photoshop conspiracies begin!'\n",
      "\n",
      "White House communications director Dan Pfeiffer also joined in the teasing and tweeted the picture of the President with a shout-out to the 'skeeters' - namely people who might claim the image is false.\n",
      "\n",
      "Both men received a large amount of online abuse for their attempts at humor.\n",
      "\n",
      "The image of a U.S. president holding a gun is certainly nothing new. A number of men who have held the highest office in America have been pictured holding guns, from Theodore Roosevelt to George W. Bush.\n",
      "\n",
      "\n",
      "Sample0:  President Obama's skeet shooting photo was released on Saturday morning, hours after the White House released a photo of him shooting at a clay pigeon\n",
      "\n",
      "The photo was taken on Aug. 4. It shows the president holding a shotgun and a skeet-shooting rifle\n",
      "\n",
      "\n",
      "Sample1:  Obama has a skeet shooting hobby, but he doesn't like to show it off.<|endoftext|>\n",
      "Sample2:  The White House released a picture of President Obama skeet shooting on Saturday morning. It was taken at Camp David, which is where the president has been staying since October. The image was taken by White House photographer Pete Souza.\n",
      "\n",
      "Obama has long been a keen shooter, and he has been pictured shooting skeet in his youth.\n",
      "\n",
      "Sample3:  President Obama has no idea what he's doing and his White House photoshop team is trying to make him look like a badass\n",
      "\n",
      "The president's wife Michelle, who has been photographed holding a gun, has also been photographed in her underwear.\n",
      "\n",
      "The president has also been pictured holding a rifle and a pistol, though not in the same pose.\n",
      "\n",
      "Best: 2\n",
      "=== cnndm_online_45k.json: 46545 ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>sample0</th>\n",
       "      <th>sample1</th>\n",
       "      <th>sample2</th>\n",
       "      <th>sample3</th>\n",
       "      <th>best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[7571, 1528, 878, 1992, 8732, 2486, 338, 717, ...</td>\n",
       "      <td>[1992, 2486, 338, 6146, 316, 4395, 4590, 373, ...</td>\n",
       "      <td>[2486, 468, 257, 6146, 316, 4395, 20005, 11, 4...</td>\n",
       "      <td>[383, 2635, 2097, 2716, 257, 4286, 286, 1992, ...</td>\n",
       "      <td>[1992, 2486, 468, 645, 2126, 644, 339, 338, 18...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[32, 10614, 5858, 14716, 24105, 656, 257, 6908...</td>\n",
       "      <td>[317, 10614, 5858, 14716, 24105, 656, 257, 690...</td>\n",
       "      <td>[383, 10614, 5858, 286, 257, 3155, 287, 28847,...</td>\n",
       "      <td>[317, 15291, 10614, 5858, 373, 14716, 5710, 65...</td>\n",
       "      <td>[317, 10614, 5858, 14716, 5710, 656, 257, 6908...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[10364, 8732, 2486, 284, 8279, 625, 262, 4960,...</td>\n",
       "      <td>[383, 471, 13, 50, 13, 1893, 318, 262, 717, 55...</td>\n",
       "      <td>[2486, 318, 257, 1256, 25242, 621, 262, 4960, ...</td>\n",
       "      <td>[383, 1893, 373, 21272, 416, 16755, 1524, 1719...</td>\n",
       "      <td>[383, 1893, 373, 21272, 416, 16755, 1524, 1719...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  [7571, 1528, 878, 1992, 8732, 2486, 338, 717, ...   \n",
       "1  [32, 10614, 5858, 14716, 24105, 656, 257, 6908...   \n",
       "2  [10364, 8732, 2486, 284, 8279, 625, 262, 4960,...   \n",
       "\n",
       "                                             sample0  \\\n",
       "0  [1992, 2486, 338, 6146, 316, 4395, 4590, 373, ...   \n",
       "1  [317, 10614, 5858, 14716, 24105, 656, 257, 690...   \n",
       "2  [383, 471, 13, 50, 13, 1893, 318, 262, 717, 55...   \n",
       "\n",
       "                                             sample1  \\\n",
       "0  [2486, 468, 257, 6146, 316, 4395, 20005, 11, 4...   \n",
       "1  [383, 10614, 5858, 286, 257, 3155, 287, 28847,...   \n",
       "2  [2486, 318, 257, 1256, 25242, 621, 262, 4960, ...   \n",
       "\n",
       "                                             sample2  \\\n",
       "0  [383, 2635, 2097, 2716, 257, 4286, 286, 1992, ...   \n",
       "1  [317, 15291, 10614, 5858, 373, 14716, 5710, 65...   \n",
       "2  [383, 1893, 373, 21272, 416, 16755, 1524, 1719...   \n",
       "\n",
       "                                             sample3  best  \n",
       "0  [1992, 2486, 468, 645, 2126, 644, 339, 338, 18...     2  \n",
       "1  [317, 10614, 5858, 14716, 5710, 656, 257, 6908...     2  \n",
       "2  [383, 1893, 373, 21272, 416, 16755, 1524, 1719...     2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Two days before President Barack Obama's first trip outside Washington to promote his gun-control proposals, the White House tried on Saturday to settle a brewing mystery by releasing a photo to back his claim to be a skeet shooter.\n",
      "\n",
      "Obama had set inquiring minds spinning when, in an interview with The New Republic magazine, he answered 'yes' when asked if he had ever fired a gun. The admission came as a surprise to many.\n",
      "\n",
      "'Yes, in fact, up at Camp David, we do skeet shooting all the time,' Obama said in the interview released last weekend, referring to the official presidential retreat in rural Maryland, which he last visited in October while campaigning for re-election.\n",
      "\n",
      "Guns a blazing: The White House released this picture, taken on Aug. 4, of the president skeet shooting after skeptics questioned Mr Obama's claim that he enjoyed shooting at Camp David\n",
      "\n",
      "Former White House senior adviser David Plouffe took to Twitter to mock those who might claim the photograph of President Obama shooting a firearm is fake\n",
      "\n",
      "White House communications director Dan Pfeiffer joined in the teasing by posting the Obama pic from his official Twitter account\n",
      "\n",
      "George W. Bush looks to the sky during a dove hunt in Hockley, Texas in 2004\n",
      "\n",
      "Asked whether the entire family participates, the president said: 'Not the girls, but oftentimes guests of mine go up there.'\n",
      "\n",
      "Then on Saturday morning, the White House released the photo of Obama \n",
      "shooting at clay pigeons at the presidential retreat at Camp David in \n",
      "Maryland.\n",
      "\n",
      "Former White House senior adviser David Plouffe couldn't resist mocking those who might claim the photograph of President \n",
      "Obama shooting was fake and tweeted: 'Attention skeet birthers. Make our day - let the photoshop conspiracies begin!'\n",
      "\n",
      "White House communications director Dan Pfeiffer also joined in the teasing and tweeted the picture of the President with a shout-out to the 'skeeters' - namely people who might claim the image is false.\n",
      "\n",
      "Both men received a large amount of online abuse for their attempts at humor.\n",
      "\n",
      "The image of a U.S. president holding a gun is certainly nothing new. A number of men who have held the highest office in America have been pictured holding guns, from Theodore Roosevelt to George W. Bush.\n",
      "\n",
      "\n",
      "Sample0:  President Obama's skeet shooting photo was released on Saturday morning, hours after the White House released a photo of him shooting at a clay pigeon\n",
      "\n",
      "The photo was taken on Aug. 4. It shows the president holding a shotgun and a skeet-shooting rifle\n",
      "\n",
      "\n",
      "Sample1:  Obama has a skeet shooting hobby, but he doesn't like to show it off.<|endoftext|>\n",
      "Sample2:  The White House released a picture of President Obama skeet shooting on Saturday morning. It was taken at Camp David, which is where the president has been staying since October. The image was taken by White House photographer Pete Souza.\n",
      "\n",
      "Obama has long been a keen shooter, and he has been pictured shooting skeet in his youth.\n",
      "\n",
      "Sample3:  President Obama has no idea what he's doing and his White House photoshop team is trying to make him look like a badass\n",
      "\n",
      "The president's wife Michelle, who has been photographed holding a gun, has also been photographed in her underwear.\n",
      "\n",
      "The president has also been pictured holding a rifle and a pistol, though not in the same pose.\n",
      "\n",
      "Best: 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_11284/1989285678.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;28;01min\u001b[39;00m DATA_FILENAME:\n\u001b[32m      2\u001b[39m     df = pd.read_json(f'{PROJECT_DIR}/data/{filename}')\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     print(f\"=== {filename}: {len(df)} ===\")\n\u001b[32m      4\u001b[39m     display(df.head(\u001b[32m3\u001b[39m))\n\u001b[32m      5\u001b[39m     row = df.iloc[\u001b[32m0\u001b[39m]\n\u001b[32m      6\u001b[39m     print(f\"Query: {tokenizer.decode(row[\u001b[33m'query'\u001b[39m])}\")\n",
      "\u001b[32m~/.cache/pypoetry/virtualenvs/finetuning-lm-from-human-preferences-4SAAosyV-py3.12/lib/python3.12/site-packages/pandas/core/frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1643\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m __len__(self) -> int:\n\u001b[32m   1644\u001b[39m         \"\"\"\n\u001b[32m   1645\u001b[39m         Returns length of info axis, but here we use the index.\n\u001b[32m   1646\u001b[39m         \"\"\"\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for filename in DATA_FILENAME:\n",
    "    df = pd.read_json(f'{PROJECT_DIR}/data/{filename}')\n",
    "    print(f\"=== {filename}: {len(df)} ===\")\n",
    "    display(df.head(3))\n",
    "    row = df.iloc[0]\n",
    "    print(f\"Query: {tokenizer.decode(row['query'])}\")\n",
    "    print(f\"Sample0: {tokenizer.decode(row['sample0'])}\")\n",
    "    print(f\"Sample1: {tokenizer.decode(row['sample1'])}\")\n",
    "    print(f\"Sample2: {tokenizer.decode(row['sample2'])}\")\n",
    "    print(f\"Sample3: {tokenizer.decode(row['sample3'])}\")\n",
    "    print(f\"Best: {row['best']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATA_FILENAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = pd.read_json(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m../data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mDATA_FILENAME\u001b[49m[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'DATA_FILENAME' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_json(f'{PROJECT_DIR}/data/{DATA_FILENAME[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "\n",
    "# Define the path to the JSON file\n",
    "json_file_path = '../data/descriptiveness_offline_5k.json'\n",
    "\n",
    "# Load the JSON data\n",
    "with open(json_file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "model_name = \"openai-community/gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.gpt2.tokenization_gpt2_fast.GPT2TokenizerFast"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[31373,  2506],\n",
       "        [ 9288, 50256]]), 'attention_mask': tensor([[1, 1],\n",
       "        [1, 0]])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "text = [\n",
    "    'hello everyone',\n",
    "    'test'\n",
    "]\n",
    "tokenizer(text, return_tensors='pt', padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  query  \\\n",
      "0     [6542, 3114, 866, 11, 290, 2497, 606, 3393, 13...   \n",
      "1     [1318, 318, 645, 835, 314, 1101, 1016, 284, 30...   \n",
      "2     [198, 6, 35284, 284, 766, 407, 2506, 318, 7195...   \n",
      "3     [679, 373, 1642, 503, 351, 1194, 2576, 826, 78...   \n",
      "4     [383, 6608, 314, 5839, 389, 287, 370, 343, 461...   \n",
      "...                                                 ...   \n",
      "6255  [2399, 1995, 373, 3393, 319, 465, 1735, 11, 14...   \n",
      "6256  [2399, 1995, 373, 3393, 319, 465, 1735, 11, 14...   \n",
      "6257  [2399, 1995, 373, 3393, 319, 465, 1735, 11, 14...   \n",
      "6258  [2399, 1995, 373, 3393, 319, 465, 1735, 11, 14...   \n",
      "6259  [2399, 1995, 373, 3393, 319, 465, 1735, 11, 14...   \n",
      "\n",
      "                                                sample0  \\\n",
      "0     [383, 582, 351, 262, 21213, 3114, 29627, 5385,...   \n",
      "1     [314, 2513, 503, 286, 262, 14043, 290, 766, 61...   \n",
      "2     [198, 6, 5195, 338, 673, 1804, 3734, 8348, 198...   \n",
      "3     [314, 373, 523, 7954, 379, 683, 290, 314, 2227...   \n",
      "4     [366, 1532, 345, 761, 597, 1037, 11, 1309, 502...   \n",
      "...                                                 ...   \n",
      "6255  [2399, 9955, 550, 1464, 587, 1498, 284, 1630, ...   \n",
      "6256  [2399, 9955, 550, 1464, 587, 1498, 284, 1630, ...   \n",
      "6257  [2399, 9955, 550, 1464, 587, 1498, 284, 1630, ...   \n",
      "6258  [2399, 9955, 550, 1464, 587, 1498, 284, 1630, ...   \n",
      "6259  [2399, 9955, 550, 1464, 587, 1498, 284, 1630, ...   \n",
      "\n",
      "                                                sample1  \\\n",
      "0     [198, 198, 1, 2061, 262, 5968, 318, 326, 1517,...   \n",
      "1     [383, 6510, 389, 477, 5586, 379, 262, 3084, 11...   \n",
      "2     [705, 464, 23684, 318, 625, 13, 1318, 338, 257...   \n",
      "3     [314, 1422, 470, 765, 284, 1254, 262, 835, 314...   \n",
      "4     [366, 464, 7541, 318, 1682, 262, 1266, 11, 101...   \n",
      "...                                                 ...   \n",
      "6255  [198, 1, 2061, 318, 340, 11, 3367, 1701, 198, ...   \n",
      "6256  [198, 1, 2061, 318, 340, 11, 3367, 1701, 198, ...   \n",
      "6257  [198, 1, 2061, 318, 340, 11, 3367, 1701, 198, ...   \n",
      "6258  [198, 1, 2061, 318, 340, 11, 3367, 1701, 198, ...   \n",
      "6259  [198, 1, 2061, 318, 340, 11, 3367, 1701, 198, ...   \n",
      "\n",
      "                                                sample2  \\\n",
      "0     [198, 1, 2061, 318, 340, 1701, 6542, 1965, 13,...   \n",
      "1     [632, 17603, 502, 286, 618, 314, 373, 257, 131...   \n",
      "2     [198, 6, 10248, 670, 4032, 1139, 5833, 273, 13...   \n",
      "3     [314, 2936, 588, 314, 373, 32249, 287, 616, 89...   \n",
      "4     [366, 40, 836, 470, 765, 284, 35117, 345, 11, ...   \n",
      "...                                                 ...   \n",
      "6255  [2399, 9955, 550, 587, 21799, 618, 339, 550, 4...   \n",
      "6256  [2399, 9955, 550, 587, 21799, 618, 339, 550, 4...   \n",
      "6257  [2399, 9955, 550, 587, 21799, 618, 339, 550, 4...   \n",
      "6258  [2399, 9955, 550, 587, 21799, 618, 339, 550, 4...   \n",
      "6259  [2399, 9955, 550, 587, 21799, 618, 339, 550, 4...   \n",
      "\n",
      "                                                sample3  best  \n",
      "0     [383, 3290, 550, 890, 11, 6546, 266, 9045, 923...     3  \n",
      "1     [314, 1949, 407, 284, 892, 546, 262, 1109, 326...     0  \n",
      "2     [705, 3347, 338, 587, 1762, 1327, 13, 1375, 33...     3  \n",
      "3     [314, 1422, 470, 765, 284, 1337, 13, 198, 198,...     3  \n",
      "4     [366, 40, 1101, 407, 6655, 345, 836, 470, 423,...     1  \n",
      "...                                                 ...   ...  \n",
      "6255  [5180, 4251, 656, 465, 736, 10000, 290, 5954, ...     3  \n",
      "6256  [5180, 4251, 656, 465, 736, 10000, 290, 5954, ...     3  \n",
      "6257  [5180, 4251, 656, 465, 736, 10000, 290, 5954, ...     0  \n",
      "6258  [5180, 4251, 656, 465, 736, 10000, 290, 5954, ...     3  \n",
      "6259  [5180, 4251, 656, 465, 736, 10000, 290, 5954, ...     3  \n",
      "\n",
      "[6260 rows x 6 columns]\n",
      "\n",
      "'Nice to see not everyone is suffering,' I say. 'How's Ijju?'\n",
      "'She's doing fine,' says Castor, zooming in on Algeria.\n"
     ]
    }
   ],
   "source": [
    "# tokenizer.decode(data[0]['query'], skip_special_tokens=True)\n",
    "df = pd.read_json('../data/descriptiveness_offline_5k.json')\n",
    "row = df.iloc[2]\n",
    "print(df)\n",
    "print(tokenizer.decode(row['query'], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From created datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ez/.cache/pypoetry/virtualenvs/finetuning-lm-from-human-preferences-4SAAosyV-py3.12/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['query', 'sample0', 'sample1', 'sample2', 'sample3', 'best'],\n",
      "    num_rows: 6260\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "FILENAME = '../data/descriptiveness_offline_5k'\n",
    "\n",
    "dataset = datasets.load_from_disk(FILENAME)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [39305], 'attention_mask': [1]}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer('abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6542, 3114, 866, 11, 290, 2497, 606, 3393, 13, 679, 635, 2497, 484, 547, 2045, 3264, 736, 379, 683, 13, 1318, 373, 257, 582, 351, 257, 1336, 21213, 11, 1194, 582, 21804, 319, 257, 33009, 11, 290, 257, 6283, 12, 11534, 427, 363, 1360, 2330, 12, 392, 12, 33282, 3290, 326, 373, 4988, 1311, 506, 516, 287, 2546, 13]\n",
      "[6542, 3114, 866, 11, 290, 2497, 606, 3393, 13, 679, 635, 2497, 484, 547, 2045, 3264, 736, 379, 683, 13, 1318, 373, 257, 582, 351, 257, 1336, 21213, 11, 1194, 582, 21804, 319, 257, 33009, 11, 290, 257, 6283, 12, 11534, 427, 363, 1360, 2330, 12, 392, 12, 33282, 3290, 326, 373, 4988, 1311, 506, 516, 287, 2546, 13]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
    "\n",
    "sample_dataset = dataset.select(range(50))\n",
    "tokenizer = AutoTokenizer.from_pretrained('openai-community/gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "sample_dataset = sample_dataset.map(lambda x: {'input_ids': tokenizer(x[\"query\"])['input_ids']}, remove_columns=sample_dataset.column_names)\n",
    "print(sample_dataset[0]['input_ids'])\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    sample_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    drop_last=True,  # needed; otherwise the last batch will be of ragged shape\n",
    ")\n",
    "\n",
    "iter_dataloader = iter(repeated_generator())\n",
    "data = next(iter_dataloader)\n",
    "print(data['input_ids'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetuning-lm-from-human-preferences-4SAAosyV-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
